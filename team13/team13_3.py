# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°


# ============================================
# Step 5ï¼šLightGBM ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ”¹å–„ç‰ˆï¼‰
# ============================================

!pip install optuna -q

import optuna
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import pandas as pd

# --- ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæ–‡å­—åŒ–ã‘é˜²æ­¢ï¼‰ ---
font_candidates = [f for f in fm.findSystemFonts() if "ipag" in f.lower()]
font_path = font_candidates[0]
fm.fontManager.addfont(font_path)
prop = fm.FontProperties(fname=font_path)
mpl.rcParams["font.family"] = prop.get_name()
mpl.rcParams["axes.unicode_minus"] = False

print("âœ… Step5 æ”¹å–„ç‰ˆ - LightGBM Ã— Optuna å®Ÿè¡Œé–‹å§‹")

# ============================================
# â‘  ç‰¹å¾´é‡ãƒ»ç›®çš„å¤‰æ•°ã®è¨­å®šï¼ˆStep4ã§ä½¿ç”¨ã—ãŸ df ã‚’å‰æï¼‰
# ============================================
# ğŸ‘‰ æ´¾ç”Ÿç‰¹å¾´é‡ã®ã†ã¡ãƒã‚¤ã‚ºå‚¾å‘ã®å¼·ã„ã‚‚ã®ã‚’å‰Šé™¤
features = [
    "temperature", "humidity", "wind_speed", "electricity",
    "gas_lag_24", "gas_lag_168", "hour", "dow", "is_holiday"
]
target = "gas_usage"

X = df[features]
y = df[target]

X_train, X_valid, y_train, y_valid = train_test_split(
    X, y, test_size=0.2, shuffle=False
)

# ============================================
# â‘¡ Optuna ã«ã‚ˆã‚‹å®‰å®šæ¢ç´¢ï¼ˆéå­¦ç¿’æŠ‘åˆ¶ãƒ»æ¢ç´¢ç¯„å›²èª¿æ•´ï¼‰
# ============================================

def objective(trial):
    params = {
        "objective": "regression",
        "metric": "rmse",
        "verbosity": -1,
        "boosting_type": "gbdt",
        "learning_rate": trial.suggest_float("learning_rate", 0.02, 0.1),
        "max_depth": trial.suggest_int("max_depth", 4, 8),
        "num_leaves": trial.suggest_int("num_leaves", 31, 120),
        "subsample": trial.suggest_float("subsample", 0.8, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.8, 1.0),
        "min_child_samples": trial.suggest_int("min_child_samples", 20, 60),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 1.0),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 1.0),
        "random_state": 42,
        "n_estimators": 1000
    }

    model = lgb.LGBMRegressor(**params)
    model.fit(
        X_train,
        y_train,
        eval_set=[(X_valid, y_valid)],
        eval_metric="rmse",
        callbacks=[lgb.early_stopping(50)]  # æ—©æœŸçµ‚äº†ã§éå­¦ç¿’é˜²æ­¢
    )

    y_pred = model.predict(X_valid)
    rmse = mean_squared_error(y_valid, y_pred) ** 0.5
    return rmse

# --- è©¦è¡Œå›æ•°ã‚’æ‹¡å¤§ï¼ˆç²¾åº¦å®‰å®šåŒ–ï¼‰ ---
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=60, show_progress_bar=True)

# ============================================
# â‘¢ ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†å­¦ç¿’
# ============================================
best_params = study.best_params
print("\nâœ… æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for k, v in best_params.items():
    print(f"  {k}: {v}")

best_model = lgb.LGBMRegressor(**best_params)
best_model.fit(X_train, y_train)
y_pred_best = best_model.predict(X_valid)

rmse_best = mean_squared_error(y_valid, y_pred_best) ** 0.5
r2_best = r2_score(y_valid, y_pred_best)

print(f"\nã€æœ€é©ãƒ¢ãƒ‡ãƒ«çµæœã€‘RMSE={rmse_best:.2f}, RÂ²={r2_best:.3f}")

# ============================================
# â‘£ Step4ã¨ã®æ¯”è¼ƒï¼ˆRMSE / RÂ²ï¼‰
# ============================================

# Step4ï¼ˆå‰å›ã®çµæœï¼‰
rmse_step4 = 9.15
r2_step4 = 0.893

compare_df = pd.DataFrame({
    "ãƒ¢ãƒ‡ãƒ«": ["Step4ï¼ˆåŸºæœ¬ï¼‰", "Step5ï¼ˆæ”¹å–„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰"],
    "RMSE": [rmse_step4, rmse_best],
    "RÂ²": [r2_step4, r2_best]
})
display(compare_df)

# --- å¯è¦–åŒ–ï¼ˆæ£’ã‚°ãƒ©ãƒ•ã§æ¯”è¼ƒï¼‰ ---
fig, ax1 = plt.subplots(figsize=(7,4))
ax2 = ax1.twinx()
width = 0.35

ax1.bar([0 - width/2, 1 - width/2], compare_df["RMSE"], width, label="RMSE", color="#6fa8dc")
ax2.bar([0 + width/2, 1 + width/2], compare_df["RÂ²"], width, label="RÂ²", color="#93c47d")

ax1.set_ylabel("RMSEï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰", fontproperties=prop)
ax2.set_ylabel("RÂ²ï¼ˆå¤§ãã„ã»ã©è‰¯ã„ï¼‰", fontproperties=prop)
plt.xticks([0,1], compare_df["ãƒ¢ãƒ‡ãƒ«"], fontproperties=prop)
plt.title("Step4 vs Step5ï¼ˆæ”¹å–„å¾Œï¼‰ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", fontproperties=prop)
fig.legend(loc="upper right")
plt.tight_layout()
plt.show()

# ============================================
# â‘¤ ç‰¹å¾´é‡é‡è¦åº¦ã®å†ç¢ºèª
# ============================================
importance = pd.DataFrame({
    "ç‰¹å¾´é‡": X_train.columns,
    "é‡è¦åº¦": best_model.feature_importances_
}).sort_values("é‡è¦åº¦", ascending=False)

plt.figure(figsize=(8,5))
plt.barh(importance["ç‰¹å¾´é‡"][::-1], importance["é‡è¦åº¦"][::-1])
plt.title("æœ€é©åŒ–å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆLightGBM + Optuna æ”¹å–„ç‰ˆï¼‰", fontproperties=prop)
plt.xlabel("é‡è¦åº¦ã‚¹ã‚³ã‚¢", fontproperties=prop)
plt.tight_layout()
plt.show()

display(importance)
